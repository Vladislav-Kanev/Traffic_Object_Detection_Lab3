{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "from torchvision.io import read_image\n",
    "from torchvision.ops.boxes import masks_to_boxes\n",
    "from torchvision import tv_tensors\n",
    "from torchvision.transforms.v2 import functional as F\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'models'...\n",
      "remote: Enumerating objects: 4050, done.\u001b[K\n",
      "remote: Counting objects: 100% (4050/4050), done.\u001b[K\n",
      "remote: Compressing objects: 100% (3078/3078), done.\u001b[K\n",
      "remote: Total 4050 (delta 1185), reused 2789 (delta 914), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (4050/4050), 54.69 MiB | 5.12 MiB/s, done.\n",
      "Resolving deltas: 100% (1185/1185), done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "if  \"models\"  in pathlib.Path.cwd().parts:\n",
    "   while  \"models\"  in pathlib.Path.cwd().parts:\n",
    "    os.chdir('..')\n",
    "elif  not pathlib.Path('models').exists():\n",
    "\t!git clone --depth 1 https://github.com/tensorflow/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 0, 'name': 'obstacles', 'supercategory': 'none'},\n",
       " {'id': 1, 'name': 'biker', 'supercategory': 'obstacles'},\n",
       " {'id': 2, 'name': 'car', 'supercategory': 'obstacles'},\n",
       " {'id': 3, 'name': 'pedestrian', 'supercategory': 'obstacles'},\n",
       " {'id': 4, 'name': 'trafficLight', 'supercategory': 'obstacles'},\n",
       " {'id': 5, 'name': 'trafficLight-Green', 'supercategory': 'obstacles'},\n",
       " {'id': 6, 'name': 'trafficLight-GreenLeft', 'supercategory': 'obstacles'},\n",
       " {'id': 7, 'name': 'trafficLight-Red', 'supercategory': 'obstacles'},\n",
       " {'id': 8, 'name': 'trafficLight-RedLeft', 'supercategory': 'obstacles'},\n",
       " {'id': 9, 'name': 'trafficLight-Yellow', 'supercategory': 'obstacles'},\n",
       " {'id': 10, 'name': 'trafficLight-YellowLeft', 'supercategory': 'obstacles'},\n",
       " {'id': 11, 'name': 'truck', 'supercategory': 'obstacles'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file = open('data/usdc_train.json')\n",
    " \n",
    "data = json.load(train_file)\n",
    " \n",
    "classes = data['categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.42s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CocoDetection\n",
    "from torchvision.transforms import functional as F\n",
    "from torch.optim import SGD\n",
    "import torchvision.transforms as T\n",
    "import os\n",
    "\n",
    "# Load and explore the data\n",
    "data_path = \"data/\"\n",
    "train_annotations_path = os.path.join(data_path, \"usdc_train.json\")\n",
    "train_images_path = os.path.join(data_path, \"train_images/train_images\")\n",
    "\n",
    "# Load the COCO dataset\n",
    "dataset = CocoDetection(root=train_images_path, annFile=train_annotations_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import (\n",
    "    HorizontalFlip,\n",
    "    RandomBrightnessContrast,\n",
    "    Rotate,\n",
    "    Compose,\n",
    "    Resize,\n",
    "    Normalize,\n",
    ")\n",
    "\n",
    "def get_train_transform():\n",
    "    return Compose([\n",
    "        HorizontalFlip(p=0.5),\n",
    "        RandomBrightnessContrast(p=0.2),\n",
    "        Rotate(limit=10, p=0.5),\n",
    "        Resize(512, 512),  # Adjust size as needed\n",
    "        Normalize(),  # You can experiment with different normalization techniques\n",
    "    ], bbox_params={'format': 'coco'})\n",
    "\n",
    "def get_test_transform():\n",
    "    return Compose([\n",
    "        Resize(512, 512),\n",
    "        Normalize(),\n",
    "    ], bbox_params={'format': 'coco'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import functional as F\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataset, transforms=None):\n",
    "        self.dataset = dataset\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, target = self.dataset[idx]\n",
    "        image = F.to_tensor(image)\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            augmented = self.transforms(image=image, bboxes=target['boxes'], labels=target['labels'])\n",
    "            image = augmented['image']\n",
    "            target['boxes'] = torch.tensor(augmented['bboxes'])\n",
    "        \n",
    "        return image, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "# Create train and test datasets\n",
    "train_dataset = CustomDataset(dataset, transforms=get_train_transform())\n",
    "test_dataset = CustomDataset(dataset, transforms=get_test_transform())\n",
    "\n",
    "# Create train and test data loaders\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=4)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=2, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
